{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96e0a36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving notices: ...working... done\n",
      "Channels:\n",
      " - pytorch\n",
      " - defaults\n",
      " - conda-forge\n",
      "Platform: win-64\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: c:\\Users\\conno\\anaconda3\\envs\\ee467\n",
      "\n",
      "  added / updated specs:\n",
      "    - cpuonly\n",
      "    - pytorch\n",
      "    - torchaudio\n",
      "    - torchvision\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    _openmp_mutex-4.5          |            2_gnu          48 KB  conda-forge\n",
      "    brotlicffi-1.2.0.0         |  py311h885b0b7_0         348 KB\n",
      "    certifi-2026.01.04         |  py311haa95532_0         148 KB\n",
      "    cffi-2.0.0                 |  py311h02ab6af_1         298 KB\n",
      "    charset-normalizer-3.4.4   |  py311haa95532_0         125 KB\n",
      "    cpuonly-2.0                |                0           2 KB  pytorch\n",
      "    filelock-3.20.3            |  py311haa95532_0          39 KB\n",
      "    gmp-6.3.0                  |       h537511b_0         330 KB\n",
      "    gmpy2-2.2.2                |  py311h8598115_0         212 KB\n",
      "    idna-3.11                  |  py311haa95532_0         200 KB\n",
      "    intel-openmp-2025.0.0      |    haa95532_1164         2.1 MB\n",
      "    jinja2-3.1.6               |  py311haa95532_0         359 KB\n",
      "    lcms2-2.17                 |       hbcf6048_0         499 KB  conda-forge\n",
      "    lerc-4.0.0                 |       h5da7b33_0         185 KB\n",
      "    libdeflate-1.22            |       h2466b09_0         152 KB  conda-forge\n",
      "    libfreetype-2.14.1         |       h57928b3_0           8 KB  conda-forge\n",
      "    libfreetype6-2.14.1        |       hdbac1cb_0         332 KB  conda-forge\n",
      "    libgcc-15.2.0              |      h8ee18e1_16         800 KB  conda-forge\n",
      "    libgomp-15.2.0             |      h8ee18e1_16         648 KB  conda-forge\n",
      "    libjpeg-turbo-3.1.3        |       h02ab6af_0         838 KB\n",
      "    libopenjpeg-2.5.4          |       h02ab6af_1         183 KB\n",
      "    libpng-1.6.54              |       ha15c746_0         239 KB\n",
      "    libtiff-4.7.0              |       hfc51747_1         956 KB  conda-forge\n",
      "    libuv-1.48.0               |       h827c3e9_0         322 KB\n",
      "    libwebp-1.6.0              |       h4d5522a_0          71 KB  conda-forge\n",
      "    libwebp-base-1.6.0         |       hbf3958f_0         279 KB\n",
      "    libwinpthread-12.0.0.r4.gg4f2fc60ca|      h57928b3_10          36 KB  conda-forge\n",
      "    libxcb-1.17.0              |       h0e4246c_0         1.2 MB  conda-forge\n",
      "    markupsafe-3.0.2           |  py311h827c3e9_0          39 KB\n",
      "    mkl-2023.1.0               |   h6a75c08_48682       137.2 MB  conda-forge\n",
      "    mkl-service-2.4.0          |  py311h827c3e9_2          67 KB\n",
      "    mkl_fft-1.3.11             |  py311h827c3e9_0         176 KB\n",
      "    mkl_random-1.2.8           |  py311hea22821_0         266 KB\n",
      "    mpc-1.3.1                  |       h827c3e9_0          85 KB\n",
      "    mpfr-4.2.1                 |       h56c3642_0         266 KB\n",
      "    mpmath-1.3.0               |  py311haa95532_0         1.0 MB\n",
      "    networkx-3.6.1             |  py311haa95532_0         3.2 MB\n",
      "    numpy-2.0.1                |  py311hdab7c0b_1          11 KB\n",
      "    numpy-base-2.0.1           |  py311hd01c5d8_1         9.6 MB\n",
      "    openjpeg-2.5.4             |       h56d5a42_1          93 KB\n",
      "    pillow-11.3.0              |  py311h26a3c52_3         927 KB  conda-forge\n",
      "    pthread-stubs-0.3          |       h3c9f919_1           7 KB\n",
      "    pycparser-2.23             |  py311haa95532_0         264 KB\n",
      "    pysocks-1.7.1              |  py311haa95532_1          36 KB\n",
      "    pytorch-2.5.1              |     py3.11_cpu_0       151.3 MB  pytorch\n",
      "    pytorch-mutex-1.0          |              cpu           3 KB  pytorch\n",
      "    pyyaml-6.0.3               |  py311hb9a58be_0         233 KB\n",
      "    requests-2.32.5            |  py311haa95532_1         167 KB\n",
      "    sympy-1.14.0               |  py311haa95532_1        14.7 MB\n",
      "    torchaudio-2.5.1           |        py311_cpu         5.9 MB  pytorch\n",
      "    torchvision-0.20.1         |        py311_cpu         6.8 MB  pytorch\n",
      "    urllib3-2.6.3              |  py311haa95532_0         348 KB\n",
      "    win_inet_pton-1.1.0        |  py311haa95532_1          10 KB\n",
      "    xorg-libxau-1.0.12         |       hba3369d_1         107 KB  conda-forge\n",
      "    xorg-libxdmcp-1.1.5        |       hba3369d_1          69 KB  conda-forge\n",
      "    zstd-1.5.7                 |       h56299aa_0         645 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:       344.2 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  _openmp_mutex      conda-forge/win-64::_openmp_mutex-4.5-2_gnu \n",
      "  blas               pkgs/main/win-64::blas-1.0-mkl \n",
      "  brotlicffi         pkgs/main/win-64::brotlicffi-1.2.0.0-py311h885b0b7_0 \n",
      "  certifi            pkgs/main/win-64::certifi-2026.01.04-py311haa95532_0 \n",
      "  cffi               pkgs/main/win-64::cffi-2.0.0-py311h02ab6af_1 \n",
      "  charset-normalizer pkgs/main/win-64::charset-normalizer-3.4.4-py311haa95532_0 \n",
      "  cpuonly            pytorch/noarch::cpuonly-2.0-0 \n",
      "  filelock           pkgs/main/win-64::filelock-3.20.3-py311haa95532_0 \n",
      "  gmp                pkgs/main/win-64::gmp-6.3.0-h537511b_0 \n",
      "  gmpy2              pkgs/main/win-64::gmpy2-2.2.2-py311h8598115_0 \n",
      "  idna               pkgs/main/win-64::idna-3.11-py311haa95532_0 \n",
      "  intel-openmp       pkgs/main/win-64::intel-openmp-2025.0.0-haa95532_1164 \n",
      "  jinja2             pkgs/main/win-64::jinja2-3.1.6-py311haa95532_0 \n",
      "  lcms2              conda-forge/win-64::lcms2-2.17-hbcf6048_0 \n",
      "  lerc               pkgs/main/win-64::lerc-4.0.0-h5da7b33_0 \n",
      "  libdeflate         conda-forge/win-64::libdeflate-1.22-h2466b09_0 \n",
      "  libfreetype        conda-forge/win-64::libfreetype-2.14.1-h57928b3_0 \n",
      "  libfreetype6       conda-forge/win-64::libfreetype6-2.14.1-hdbac1cb_0 \n",
      "  libgcc             conda-forge/win-64::libgcc-15.2.0-h8ee18e1_16 \n",
      "  libgomp            conda-forge/win-64::libgomp-15.2.0-h8ee18e1_16 \n",
      "  libjpeg-turbo      pkgs/main/win-64::libjpeg-turbo-3.1.3-h02ab6af_0 \n",
      "  libopenjpeg        pkgs/main/win-64::libopenjpeg-2.5.4-h02ab6af_1 \n",
      "  libpng             pkgs/main/win-64::libpng-1.6.54-ha15c746_0 \n",
      "  libtiff            conda-forge/win-64::libtiff-4.7.0-hfc51747_1 \n",
      "  libuv              pkgs/main/win-64::libuv-1.48.0-h827c3e9_0 \n",
      "  libwebp            conda-forge/win-64::libwebp-1.6.0-h4d5522a_0 \n",
      "  libwebp-base       pkgs/main/win-64::libwebp-base-1.6.0-hbf3958f_0 \n",
      "  libwinpthread      conda-forge/win-64::libwinpthread-12.0.0.r4.gg4f2fc60ca-h57928b3_10 \n",
      "  libxcb             conda-forge/win-64::libxcb-1.17.0-h0e4246c_0 \n",
      "  lz4-c              pkgs/main/win-64::lz4-c-1.9.4-h2bbff1b_1 \n",
      "  markupsafe         pkgs/main/win-64::markupsafe-3.0.2-py311h827c3e9_0 \n",
      "  mkl                conda-forge/win-64::mkl-2023.1.0-h6a75c08_48682 \n",
      "  mkl-service        pkgs/main/win-64::mkl-service-2.4.0-py311h827c3e9_2 \n",
      "  mkl_fft            pkgs/main/win-64::mkl_fft-1.3.11-py311h827c3e9_0 \n",
      "  mkl_random         pkgs/main/win-64::mkl_random-1.2.8-py311hea22821_0 \n",
      "  mpc                pkgs/main/win-64::mpc-1.3.1-h827c3e9_0 \n",
      "  mpfr               pkgs/main/win-64::mpfr-4.2.1-h56c3642_0 \n",
      "  mpmath             pkgs/main/win-64::mpmath-1.3.0-py311haa95532_0 \n",
      "  networkx           pkgs/main/win-64::networkx-3.6.1-py311haa95532_0 \n",
      "  numpy              pkgs/main/win-64::numpy-2.0.1-py311hdab7c0b_1 \n",
      "  numpy-base         pkgs/main/win-64::numpy-base-2.0.1-py311hd01c5d8_1 \n",
      "  openjpeg           pkgs/main/win-64::openjpeg-2.5.4-h56d5a42_1 \n",
      "  pillow             conda-forge/win-64::pillow-11.3.0-py311h26a3c52_3 \n",
      "  pthread-stubs      pkgs/main/win-64::pthread-stubs-0.3-h3c9f919_1 \n",
      "  pycparser          pkgs/main/win-64::pycparser-2.23-py311haa95532_0 \n",
      "  pysocks            pkgs/main/win-64::pysocks-1.7.1-py311haa95532_1 \n",
      "  pytorch            pytorch/win-64::pytorch-2.5.1-py3.11_cpu_0 \n",
      "  pytorch-mutex      pytorch/noarch::pytorch-mutex-1.0-cpu \n",
      "  pyyaml             pkgs/main/win-64::pyyaml-6.0.3-py311hb9a58be_0 \n",
      "  requests           pkgs/main/win-64::requests-2.32.5-py311haa95532_1 \n",
      "  sympy              pkgs/main/win-64::sympy-1.14.0-py311haa95532_1 \n",
      "  tbb                pkgs/main/win-64::tbb-2021.8.0-h59b6b97_0 \n",
      "  torchaudio         pytorch/win-64::torchaudio-2.5.1-py311_cpu \n",
      "  torchvision        pytorch/win-64::torchvision-0.20.1-py311_cpu \n",
      "  urllib3            pkgs/main/win-64::urllib3-2.6.3-py311haa95532_0 \n",
      "  win_inet_pton      pkgs/main/win-64::win_inet_pton-1.1.0-py311haa95532_1 \n",
      "  xorg-libxau        conda-forge/win-64::xorg-libxau-1.0.12-hba3369d_1 \n",
      "  xorg-libxdmcp      conda-forge/win-64::xorg-libxdmcp-1.1.5-hba3369d_1 \n",
      "  yaml               pkgs/main/win-64::yaml-0.2.5-he774522_0 \n",
      "  zstd               pkgs/main/win-64::zstd-1.5.7-h56299aa_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages: ...working... done\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install pytorch torchvision torchaudio cpuonly -c pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42e541f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] DEVICE: cpu\n",
      "[warn] Could not load ./labels.pkl; falling back to folder names: AttributeError(\"module 'numpy' has no attribute '_no_nep50_warning'\")\n",
      "[info] Inferred 32 classes from ./char-images-31528476\n",
      "[info] n_classes: 32\n",
      "[info] Total samples: 3580\n",
      "Epoch 01/10 | train loss 2.3073 acc 0.3676 | val loss 0.5806 acc 0.8581\n",
      "Epoch 02/10 | train loss 0.2946 acc 0.9274 | val loss 0.1448 acc 0.9698\n",
      "Epoch 03/10 | train loss 0.0884 acc 0.9832 | val loss 0.0918 acc 0.9866\n",
      "Epoch 04/10 | train loss 0.0533 acc 0.9899 | val loss 0.1260 acc 0.9732\n",
      "Epoch 05/10 | train loss 0.0347 acc 0.9918 | val loss 0.0932 acc 0.9765\n",
      "Epoch 06/10 | train loss 0.0147 acc 0.9978 | val loss 0.0559 acc 0.9922\n",
      "Epoch 07/10 | train loss 0.0049 acc 0.9993 | val loss 0.0639 acc 0.9888\n",
      "Epoch 08/10 | train loss 0.0154 acc 0.9952 | val loss 0.0574 acc 0.9922\n",
      "Epoch 09/10 | train loss 0.0046 acc 0.9989 | val loss 0.0554 acc 0.9955\n",
      "Epoch 10/10 | train loss 0.0104 acc 0.9981 | val loss 0.0529 acc 0.9955\n",
      "[info] Saved weights: ./captcha-model-pytorch.pt\n",
      "[result] Validation accuracy: 0.9955307262569832\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Config\n",
    "# ---------------------------\n",
    "TVT_SPLIT_SEED = 31528476\n",
    "TRAIN_VAL_SEED = 955996\n",
    "\n",
    "CHAR_IMAGE_FOLDER = f\"./char-images-{TVT_SPLIT_SEED}\"\n",
    "LABELS_PATH = \"./labels.pkl\"  # optional\n",
    "MODEL_WEIGHTS_PATH_PT = \"./captcha-model-pytorch.pt\"\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "N_EPOCHS = 10\n",
    "FORCE_TRAINING = True\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Utils\n",
    "# ---------------------------\n",
    "def resize_to_fit(image, width=20, height=20):\n",
    "    \"\"\"Resize (keep aspect ratio) then pad to exactly (height, width).\"\"\"\n",
    "    if image is None:\n",
    "        raise ValueError(\"resize_to_fit got None image\")\n",
    "\n",
    "    h, w = image.shape[:2]\n",
    "    if h == 0 or w == 0:\n",
    "        raise ValueError(f\"Bad image shape: {image.shape}\")\n",
    "\n",
    "    # Scale to fit\n",
    "    if w > h:\n",
    "        new_w = width\n",
    "        new_h = max(1, int(h * (width / w)))\n",
    "    else:\n",
    "        new_h = height\n",
    "        new_w = max(1, int(w * (height / h)))\n",
    "\n",
    "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # Pad to target size\n",
    "    padW = (width - new_w) // 2\n",
    "    padH = (height - new_h) // 2\n",
    "    image = cv2.copyMakeBorder(\n",
    "        image,\n",
    "        top=padH,\n",
    "        bottom=height - new_h - padH,\n",
    "        left=padW,\n",
    "        right=width - new_w - padW,\n",
    "        borderType=cv2.BORDER_CONSTANT,\n",
    "        value=0\n",
    "    )\n",
    "    return image\n",
    "\n",
    "\n",
    "def load_classes(char_folder, labels_path):\n",
    "    \"\"\"Load class names from labels.pkl if possible, otherwise from folder names.\"\"\"\n",
    "    classes = None\n",
    "\n",
    "    if os.path.exists(labels_path):\n",
    "        try:\n",
    "            with open(labels_path, \"rb\") as f:\n",
    "                lb = pickle.load(f)\n",
    "            classes = list(lb.classes_)\n",
    "            print(f\"[info] Loaded {len(classes)} classes from {labels_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[warn] Could not load {labels_path}; falling back to folder names: {repr(e)}\")\n",
    "\n",
    "    if classes is None:\n",
    "        classes = sorted([\n",
    "            d for d in os.listdir(char_folder)\n",
    "            if os.path.isdir(os.path.join(char_folder, d))\n",
    "        ])\n",
    "        print(f\"[info] Inferred {len(classes)} classes from {char_folder}\")\n",
    "\n",
    "    class_to_idx = {c: i for i, c in enumerate(classes)}\n",
    "    idx_to_class = {i: c for c, i in class_to_idx.items()}\n",
    "    return classes, class_to_idx, idx_to_class\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Dataset\n",
    "# ---------------------------\n",
    "class CharImagesDataset(Dataset):\n",
    "    def __init__(self, root_dir, class_to_idx, target_size=(20, 20), validate=True):\n",
    "        self.root_dir = root_dir\n",
    "        self.class_to_idx = class_to_idx\n",
    "        self.target_w, self.target_h = target_size\n",
    "\n",
    "        samples = []\n",
    "        for label in sorted(os.listdir(root_dir)):\n",
    "            label_dir = os.path.join(root_dir, label)\n",
    "            if not os.path.isdir(label_dir):\n",
    "                continue\n",
    "            if label not in class_to_idx:\n",
    "                continue\n",
    "\n",
    "            for fname in os.listdir(label_dir):\n",
    "                if fname.lower().endswith(\".png\"):\n",
    "                    samples.append((os.path.join(label_dir, fname), class_to_idx[label]))\n",
    "\n",
    "        if len(samples) == 0:\n",
    "            raise RuntimeError(f\"No PNG samples found under {root_dir}\")\n",
    "\n",
    "        if validate:\n",
    "            good = []\n",
    "            bad = 0\n",
    "            for path, y in samples:\n",
    "                img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "                if img is None or img.size == 0:\n",
    "                    bad += 1\n",
    "                    continue\n",
    "                good.append((path, y))\n",
    "            if bad:\n",
    "                print(f\"[warn] Skipped {bad} unreadable PNGs during indexing.\")\n",
    "            samples = good\n",
    "\n",
    "        self.samples = samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, y = self.samples[idx]\n",
    "\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None or img.size == 0:\n",
    "            raise ValueError(f\"Could not read image: {path}\")\n",
    "\n",
    "        img = resize_to_fit(img, self.target_w, self.target_h)\n",
    "        x = torch.tensor(img, dtype=torch.float32).unsqueeze(0) / 255.0  # (1, 20, 20)\n",
    "        y = torch.tensor(y, dtype=torch.long)\n",
    "        return x, y\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Model (same as TF architecture)\n",
    "# ---------------------------\n",
    "class CaptchaCharCNN(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 20, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(20, 50, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(5 * 5 * 50, 500),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(500, n_classes),  # logits\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.classifier(self.features(x))\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Train/Eval\n",
    "# ---------------------------\n",
    "def run_epoch(model, loader, optimizer, criterion, train=True):\n",
    "    model.train(train)\n",
    "    total_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "\n",
    "        if train:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "\n",
    "        if train:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        correct += (preds == y).sum().item()\n",
    "        total += x.size(0)\n",
    "\n",
    "    return total_loss / total, correct / total\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_accuracy(model, loader):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        logits = model(x)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        correct += (preds == y).sum().item()\n",
    "        total += x.size(0)\n",
    "    return correct / total if total else 0.0\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Basic checks\n",
    "    if not os.path.isdir(CHAR_IMAGE_FOLDER):\n",
    "        raise FileNotFoundError(\n",
    "            f\"Missing {CHAR_IMAGE_FOLDER}.\\n\"\n",
    "            \"Run your TensorFlow notebook extraction first so this folder exists.\"\n",
    "        )\n",
    "\n",
    "    print(\"[info] DEVICE:\", DEVICE)\n",
    "\n",
    "    # Seeds\n",
    "    random.seed(TVT_SPLIT_SEED)\n",
    "    np.random.seed(TVT_SPLIT_SEED)\n",
    "    torch.manual_seed(TVT_SPLIT_SEED)\n",
    "\n",
    "    # Classes\n",
    "    classes, class_to_idx, idx_to_class = load_classes(CHAR_IMAGE_FOLDER, LABELS_PATH)\n",
    "    n_classes = len(classes)\n",
    "    print(\"[info] n_classes:\", n_classes)\n",
    "\n",
    "    # Dataset\n",
    "    dataset = CharImagesDataset(CHAR_IMAGE_FOLDER, class_to_idx, target_size=(20, 20), validate=True)\n",
    "    print(\"[info] Total samples:\", len(dataset))\n",
    "\n",
    "    # Split\n",
    "    n_total = len(dataset)\n",
    "    n_val = int(0.25 * n_total)\n",
    "    n_train = n_total - n_val\n",
    "\n",
    "    train_ds, val_ds = random_split(\n",
    "        dataset,\n",
    "        [n_train, n_val],\n",
    "        generator=torch.Generator().manual_seed(TRAIN_VAL_SEED)\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "    # Model\n",
    "    model = CaptchaCharCNN(n_classes).to(DEVICE)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "    # Train or load\n",
    "    if (not FORCE_TRAINING) and os.path.exists(MODEL_WEIGHTS_PATH_PT):\n",
    "        ckpt = torch.load(MODEL_WEIGHTS_PATH_PT, map_location=DEVICE)\n",
    "        model.load_state_dict(ckpt[\"model_state_dict\"])\n",
    "        print(\"[info] Loaded weights:\", MODEL_WEIGHTS_PATH_PT)\n",
    "    else:\n",
    "        for epoch in range(1, N_EPOCHS + 1):\n",
    "            train_loss, train_acc = run_epoch(model, train_loader, optimizer, criterion, train=True)\n",
    "            val_loss, val_acc = run_epoch(model, val_loader, optimizer, criterion, train=False)\n",
    "            print(f\"Epoch {epoch:02d}/{N_EPOCHS} | \"\n",
    "                  f\"train loss {train_loss:.4f} acc {train_acc:.4f} | \"\n",
    "                  f\"val loss {val_loss:.4f} acc {val_acc:.4f}\")\n",
    "\n",
    "        torch.save({\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"classes\": classes,\n",
    "            \"class_to_idx\": class_to_idx,\n",
    "            \"idx_to_class\": idx_to_class,\n",
    "            \"n_classes\": n_classes,\n",
    "            \"tvt_split_seed\": TVT_SPLIT_SEED,\n",
    "            \"train_val_seed\": TRAIN_VAL_SEED,\n",
    "        }, MODEL_WEIGHTS_PATH_PT)\n",
    "        print(\"[info] Saved weights:\", MODEL_WEIGHTS_PATH_PT)\n",
    "\n",
    "    # Final eval\n",
    "    acc = eval_accuracy(model, val_loader)\n",
    "    print(\"[result] Validation accuracy:\", acc)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ee467",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
